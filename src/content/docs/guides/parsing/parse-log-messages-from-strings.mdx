---
title: Parse log messages from strings
---

This guide shows you how to extract structured data from text strings using
TQL's parsing functions. You'll learn to parse JSON, key-value pairs, tabular
data, standard log formats, and custom patterns with Grok.

## Parse JSON

The most common parsing task is extracting JSON from string fields. Use
[`parse_json()`](/reference/functions/parse_json):

```tql
from {message: "{\"user\": \"alice\", \"action\": \"login\"}"}
data = message.parse_json()
```

```tql
{
  message: "{\"user\": \"alice\", \"action\": \"login\"}",
  data: {user: "alice", action: "login"},
}
```

Access nested fields directly after parsing:

```tql
from {message: "{\"user\": \"alice\", \"action\": \"login\"}"}
data = message.parse_json()
user = data.user
action = data.action
```

## Extract key-value pairs

Many logs use key-value formats. [`parse_kv()`](/reference/functions/parse_kv)
handles these automatically:

```tql
from {log: "status=200 method=GET path=/api/users duration=45ms"}
fields = log.parse_kv()
```

```tql
{
  log: "status=200 method=GET path=/api/users duration=45ms",
  fields: {status: 200, method: "GET", path: "/api/users", duration: 45ms},
}
```

The function automatically detects separators and converts numeric values and
durations.

### Custom separators

Specify separators when defaults don't apply:

```tql
from {log: "user:alice action:login time:2024-01-15"}
fields = log.parse_kv(field_split=" ", value_split=":")
```

## Parse tabular data

TQL provides parsers for various tabular formats within string fields.

### CSV

Use [`parse_csv()`](/reference/functions/parse_csv):

```tql
from {line: "alice,30,engineer,SF"}
record = line.parse_csv(header=["name", "age", "role", "location"])
```

```tql
{
  line: "alice,30,engineer,SF",
  record: {name: "alice", age: 30, role: "engineer", location: "SF"},
}
```

### TSV (tab-separated)

Use [`parse_tsv()`](/reference/functions/parse_tsv):

```tql
from {line: "alice\t30\tengineer"}
record = line.parse_tsv(header=["name", "age", "role"])
```

### SSV (space-separated)

Use [`parse_ssv()`](/reference/functions/parse_ssv):

```tql
from {line: "alice 30 engineer"}
record = line.parse_ssv(header=["name", "age", "role"])
```

### Custom delimiters

Use [`parse_xsv()`](/reference/functions/parse_xsv) for arbitrary delimiters:

```tql
from {line: "alice|30|engineer|SF"}
record = line.parse_xsv(
  field_separator="|",
  header=["name", "age", "role", "location"]
)
```

## Parse standard log formats

TQL includes parsers for common log formats used in security and operations.

### Syslog

Use [`parse_syslog()`](/reference/functions/parse_syslog) for RFC 5424 and
RFC 3164 syslog messages:

```tql
from {line: "2024-01-15T10:30:45.123Z myhost myapp[1234]: User login failed"}
syslog = line.parse_syslog()
```

```tql
{
  line: "2024-01-15T10:30:45.123Z myhost myapp[1234]: User login failed",
  syslog: {
    facility: null,
    severity: null,
    timestamp: 2024-01-15T10:30:45.123Z,
    hostname: "myhost",
    app_name: "myapp",
    process_id: "1234",
    content: "User login failed",
  },
}
```

### CEF (Common Event Format)

Use [`parse_cef()`](/reference/functions/parse_cef) for security tool logs:

```tql
from {log: "CEF:0|Security|Firewall|1.0|100|Connection Blocked|5|src=10.0.0.1 dst=192.168.1.1"}
event = log.parse_cef()
```

```tql
{
  log: "CEF:0|Security|Firewall|1.0|100|Connection Blocked|5|src=10.0.0.1 dst=192.168.1.1",
  event: {
    cef_version: 0,
    device_vendor: "Security",
    device_product: "Firewall",
    device_version: "1.0",
    signature_id: "100",
    name: "Connection Blocked",
    severity: "5",
    extension: {src: 10.0.0.1, dst: 192.168.1.1},
  },
}
```

### LEEF (Log Event Extended Format)

Use [`parse_leef()`](/reference/functions/parse_leef) for IBM QRadar format:

```tql
from {log: "LEEF:1.0|Security|Firewall|1.0|100|src=10.0.0.1\tdst=192.168.1.1"}
event = log.parse_leef()
```

## Parse timestamps

Convert time strings to proper timestamp values with
[`parse_time()`](/reference/functions/parse_time):

```tql
from {log: "Event at 2024-01-15"}
timestamp = "2024-01-15".parse_time("%Y-%m-%d")
```

Common format specifiers:

| Specifier | Meaning             | Example |
| --------- | ------------------- | ------- |
| `%Y`      | 4-digit year        | 2024    |
| `%m`      | Month (01-12)       | 01      |
| `%d`      | Day (01-31)         | 15      |
| `%H`      | Hour (00-23)        | 14      |
| `%M`      | Minute (00-59)      | 30      |
| `%S`      | Second (00-59)      | 45      |
| `%b`      | Abbreviated month   | Jan     |
| `%a`      | Abbreviated weekday | Mon     |

## Use Grok patterns

For complex formats, [`parse_grok()`](/reference/functions/parse_grok) provides
powerful pattern matching:

```tql
from {log: "2024-01-15 10:30:45 ERROR [UserService] Authentication failed"}
parsed = log.parse_grok(
  "%{TIMESTAMP_ISO8601:timestamp} %{LOGLEVEL:level} \\[%{DATA:service}\\] %{GREEDYDATA:message}"
)
```

```tql
{
  log: "2024-01-15 10:30:45 ERROR [UserService] Authentication failed",
  parsed: {
    timestamp: 2024-01-15T10:30:45Z,
    level: "ERROR",
    service: "UserService",
    message: "Authentication failed",
  },
}
```

### Common Grok patterns

| Pattern                      | Matches                | Example                |
| ---------------------------- | ---------------------- | ---------------------- |
| `%{DATA:field}`              | Any chars (non-greedy) | `user123`              |
| `%{GREEDYDATA:field}`        | Any chars (greedy)     | `the rest of the line` |
| `%{NUMBER:field}`            | Numbers                | `42`, `3.14`           |
| `%{IP:field}`                | IP addresses           | `192.168.1.1`          |
| `%{TIMESTAMP_ISO8601:field}` | ISO timestamps         | `2024-01-15T10:30:45Z` |
| `%{LOGLEVEL:field}`          | Log levels             | `ERROR`, `INFO`        |
| `%{WORD:field}`              | Single word            | `hello`                |
| `%{QUOTEDSTRING:field}`      | Quoted strings         | `"hello world"`        |

## Parse YAML

Use [`parse_yaml()`](/reference/functions/parse_yaml) for YAML content:

```tql
from {config: "user: alice\nrole: admin\npermissions:\n  - read\n  - write"}
data = config.parse_yaml()
```

```tql
{
  config: "user: alice\nrole: admin\npermissions:\n  - read\n  - write",
  data: {user: "alice", role: "admin", permissions: ["read", "write"]},
}
```

## Layer multiple parsers

Real-world logs often require multiple parsing steps:

```tql
from {
  line: "2024-01-15T10:30:45Z web nginx: {\"method\":\"POST\",\"status\":401}"
}
// Step 1: Parse syslog wrapper
syslog = line.parse_syslog()
// Step 2: Parse embedded JSON
request = syslog.content.parse_json()
// Step 3: Extract specific fields
method = request.method
status = request.status
```

## Best practices

1. **Work incrementally**: Parse complex data in stages, testing each step.

2. **Handle failures gracefully**: Parsing functions return null on failure.
   Check results before accessing fields.

3. **Choose appropriate parsers**:
   - JSON/YAML for structured data
   - Key-value for simple pairs
   - CSV/TSV for tabular data
   - Syslog/CEF/LEEF for standard formats
   - Grok for custom patterns

4. **Transform after parsing**: Convert strings to proper types (timestamps,
   IPs, numbers) for efficient downstream processing.

5. **Consider performance**: Simpler parsers (JSON, KV) are faster than complex
   pattern matching (Grok).

## Related guides

- [Parse text streams into events](/guides/parsing/parse-text-streams-into-events) - Line-based byte parsing
- [Parse binary data formats](/guides/parsing/parse-binary-data-formats) - Binary format parsing
- [Transform values](/guides/transformation/transform-values) - Type conversions
