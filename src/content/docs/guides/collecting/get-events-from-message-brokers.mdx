---
title: Get events from message brokers
---

This guide shows you how to receive events from message brokers using TQL.
You'll learn to subscribe to topics and queues from Apache Kafka, AMQP-based
brokers (like RabbitMQ), Amazon SQS, and Google Cloud Pub/Sub.

## Apache Kafka

[Apache Kafka](https://kafka.apache.org) is a distributed message broker
commonly used for high-throughput event streaming. Use
[`from_kafka`](/reference/operators/from_kafka) to subscribe to topics.

### Subscribe to a topic

```tql
from_kafka "security-events"
```

By default, `from_kafka` produces events with the raw message in a `message`
field. Parse the message content to extract structured data:

```tql
from_kafka "security-events"
this = message.parse_json()
```

### Control the read offset

The `offset` option determines where to start reading:

```tql
// Start from the oldest available message
from_kafka "events", offset="beginning"

// Start from the newest messages only
from_kafka "events", offset="end"

// Resume from the last committed offset
from_kafka "events", offset="stored"

// Start from a specific offset
from_kafka "events", offset=1000

// Start 100 messages before the end
from_kafka "events", offset=-100
```

### Configure consumer groups

Kafka uses consumer groups to distribute messages across multiple consumers.
Specify a group ID for coordinated consumption:

```tql
from_kafka "events", group_id="tenzir-ingest"
```

For detailed Kafka configuration options, see the
[Kafka integration](/integrations/kafka) page.

## AMQP (RabbitMQ)

The [Advanced Message Queuing Protocol (AMQP)](https://www.amqp.org/) is
supported by brokers like RabbitMQ. Use AMQP URLs with
[`from`](/reference/operators/from) or
[`load_amqp`](/reference/operators/load_amqp) directly.

### Receive from a queue

```tql
from "amqp://user:pass@broker:5672/vhost"
```

The URL structure is `amqp://user:password@host:port/vhost`. Configure
additional options like exchange and routing key in the operator parameters.

For detailed AMQP configuration, see the [AMQP integration](/integrations/amqp)
page.

## Amazon SQS

[Amazon Simple Queue Service (SQS)](https://aws.amazon.com/sqs/) is a managed
message queue. Use [`load_sqs`](/reference/operators/load_sqs) or the `sqs://`
URL scheme.

### Receive from a queue

```tql
from "sqs://my-queue" {
  read_json
}
```

### Configure polling

Use long polling to reduce API calls and receive messages in batches:

```tql
from "sqs://my-queue", poll_interval=5s {
  read_json
}
```

SQS automatically deletes messages after successful receipt. For detailed SQS
configuration including IAM credentials, see the
[SQS integration](/integrations/amazon/sqs) page.

## Google Cloud Pub/Sub

[Google Cloud Pub/Sub](https://cloud.google.com/pubsub) provides managed
messaging for Google Cloud. Use
[`from_google_cloud_pubsub`](/reference/operators/from_google_cloud_pubsub) to
subscribe.

### Receive from a subscription

```tql
from_google_cloud_pubsub project_id="my-project",
  subscription_id="my-subscription"
parsed = message.parse_json()
```

The operator produces events with a `message` field containing the raw message
content. Parse it to extract structured data.

For detailed Pub/Sub configuration, see the
[Cloud Pub/Sub integration](/integrations/google/cloud-pubsub) page.

## Common patterns

### Parse message payloads

Most message brokers deliver raw message content that needs parsing. Common
patterns include:

```tql
// JSON messages
from_kafka "json-events"
this = message.parse_json()

// Newline-delimited JSON
from "sqs://ndjson-queue" {
  read_ndjson
}

// Custom format with Grok
from_kafka "log-events"
parsed = message.parse_grok("%{TIMESTAMP_ISO8601:ts} %{LOGLEVEL:level} %{GREEDYDATA:msg}")
```

### Add message metadata

Preserve broker-specific metadata alongside parsed content:

```tql
from_kafka "events"
payload = message.parse_json()
// The original message metadata (offset, partition, etc.) is available
// in other fields of the event
```

### Handle multiple message types

Route messages to different processing pipelines based on content:

```tql
from_kafka "mixed-events"
parsed = message.parse_json()
if parsed.type == "alert" {
  // Alert-specific processing
} else if parsed.type == "metric" {
  // Metric-specific processing
}
```

## Related guides

- [Kafka integration](/integrations/kafka) - Detailed Kafka configuration
- [AMQP integration](/integrations/amqp) - RabbitMQ and AMQP 0-9-1
- [SQS integration](/integrations/amazon/sqs) - Amazon SQS with IAM
- [Cloud Pub/Sub integration](/integrations/google/cloud-pubsub) - Google Cloud messaging
