---
title: MCP Server
---

import { Badge } from '@astrojs/starlight/components';

The [Tenzir MCP Server](https://github.com/tenzir/mcp) enables AI assistants
to interact with Tenzir through the [Model Context
Protocol](https://modelcontextprotocol.io) (MCP).

:::tip[Quick Start]
Check our [installation guide](/guides/mcp-setup/install-mcp-server) to get up
and running with the MCP Server.
:::

## What It Does

The MCP server provides a comprehensive toolkit for working with Tenzir and OCSF
through AI assistants. Built on FastMCP with a modular architecture, it offers:

- **Code Generation**: Automatically generate TQL parsers and complete OCSF
  mapping packages from sample log events.
- **Package Management**: Create, modify, and test Tenzir packages with
  user-defined operators, contexts, and tests.
- **Documentation Discovery**: Search and read embedded Tenzir documentation
  with cross-reference navigation.
- **Pipeline Execution**: Run TQL pipelines and tests directly from your AI
  conversation.
- **OCSF Schema Access**: Query OCSF schemas for classes, objects, and
  definitions.

Once you install and register the server with your MCP-aware client (for
example Claude Code, Codex, Cursor, or a custom harness), these tools become
available automatically.

## Tool Catalogue

The MCP server provides tools organized into categories for execution,
documentation, OCSF schemas, package management, and code generation. Each tool's
parameters are documented in the tool implementation and visible in your MCP client.
This page focuses on **when** to use each tool and provides usage examples.

### `run_pipeline` <Badge text="Execution" variant="danger" />

**When to use:**

- Testing TQL code before adding it to a package
- Debugging pipeline behavior with sample data
- Verifying operator syntax and semantics
- Iterating quickly on pipeline development

Pipelines run with diagnostics enabled, providing detailed error messages and warnings.

**Example:**

```python
# Execute inline TQL code
run_pipeline(pipeline="from stdin | head 5", is_file=False)

# Execute from a file
run_pipeline(pipeline="/path/to/pipeline.tql", is_file=True, max_execution_time=60)
```

### `run_test` <Badge text="Execution" variant="danger" />

**When to use:**

- Verifying package operators work correctly
- Running regression tests after making changes
- Generating test baselines (with `update=True`)
- Debugging failing tests (with `passthrough=True`)

Tests use the [`tenzir-test`](/reference/test-framework) framework and can include
fixtures like embedded Tenzir nodes for integration testing.

**Example:**

```python
# Run all tests
run_test(root="/path/to/package", selection=[])

# Run specific test
run_test(root="/path/to/package", selection=["tests/parse.tql"])

# Debug with passthrough
run_test(root="/path/to/package", selection=["tests/parse.tql"], passthrough=True)

# Generate baseline
run_test(root="/path/to/package", selection=["tests/parse.tql"], update=True)
```

### `docs_read` <Badge text="Documentation" variant="success" />

**When to use:**

- Read operator documentation **BEFORE** using any operator in TQL
- Read function documentation **BEFORE** using any function
- Study tutorials and guides for learning workflows
- List all available operators or functions

**Example:**

```python
# Read operator docs (critical before using!)
docs_read(path="reference/operators/read_json")

# List all operators
docs_read(path="reference/operators")

# Read tutorial
docs_read(path="tutorials/map-data-to-ocsf")
```

:::tip[Critical: Read Before Using]
Always read operator/function documentation before writing TQL code. This
prevents syntax errors and ensures correct usage.
:::

### `docs_search` <Badge text="Documentation" variant="success" />

**When to use:**

- Find operators or functions by keyword (e.g., "json", "parse", "filter")
- Discover related documentation through See Also links (`depth` > 0)
- Explore specific documentation areas (`search_type` filter)
- Learn about unfamiliar concepts or workflows

The `depth` parameter traverses cross-references, helping you discover operators
and functions you might not have known about.

**Example:**

```python
# Find operators by keyword
docs_search(query="json", search_type="operators")

# Discover related docs
docs_search(query="from", depth=1)
```

### `ocsf_get_versions` <Badge text="OCSF" variant="caution" />

**When to use:**

- See which OCSF schema versions are available
- Choose a specific version for your mapping work

Typically you'll want `ocsf_get_latest_version` to get the most recent stable version automatically.

### `ocsf_get_latest_version` <Badge text="OCSF" variant="caution" />

**When to use:**

- Get the current recommended OCSF version for new mappings
- Ensure you're using up-to-date schema definitions
- Start OCSF mapping workflows with the latest standard

Filters out development versions (alpha, beta, rc) and returns only stable releases.

### `ocsf_get_classes` <Badge text="OCSF" variant="caution" />

**When to use:**

- Browse available OCSF event classes before creating a mapping
- Identify which class best matches your log data
- Understand the purpose and scope of each event class

Once you identify a candidate class, use `ocsf_get_class` to see its complete schema.

**Example:**

```python
ocsf_get_classes(version="1.3.0")
```

### `ocsf_get_class` <Badge text="OCSF" variant="caution" />

**When to use:**

- Understand the full schema of an OCSF event class before mapping
- See required vs optional fields
- Discover nested object structures and their field definitions
- Validate that your source data can map to the class

Returns the complete class definition including all attributes, types, and constraints.

**Example:**

```python
ocsf_get_class(version="1.3.0", name="Network Activity")
```

### `ocsf_get_object` <Badge text="OCSF" variant="caution" />

**When to use:**

- Understand complex nested object structures in OCSF classes
- See the fields and types within objects like 'file', 'process', 'user'
- Map source data to nested OCSF structures correctly

Objects are reusable components within OCSF event classes, defining standard structures.

**Example:**

```python
ocsf_get_object(version="1.3.0", name="process")
```

### `package_create` <Badge text="Packaging" variant="tip" />

**When to use:**

- Start a new Tenzir package project
- Set up the standard directory structure for operators, tests, and documentation
- Initialize package metadata (ID, name, author, description)

Creates the foundation for building custom TQL operators, parsers, and OCSF mappings.

**Example:**

```python
package_create(package_dir="/tmp/my-ocsf-parser")
# Creates: operators/, pipelines/, tests/inputs/, changelog/
# Generates: package.yaml, README.md
```

### `package_add_operator` <Badge text="Packaging" variant="tip" />

**When to use:**

- Add custom TQL operators to your package
- Organize operators using nested namespaces (e.g., `ocsf::logs::firewall`)
- Create parsers, transformations, or OCSF mappings as reusable operators
- Automatically generate test scaffolds for new operators

Operators become available as `package_id::operator_name` in TQL pipelines after installation.

**Example:**

```python
# Simple operator
package_add_operator(
    package_dir="/tmp/my-package",
    name="parse",
    description="Parse custom log format",
    code="read_json | unflatten"
)

# Nested namespace
package_add_operator(
    package_dir="/tmp/my-package",
    name="ocsf::logs::firewall",
    description="Parse firewall logs to OCSF",
    code="read_json | unflatten"
)
```

### `package_add_context` <Badge text="Packaging" variant="tip" />

**When to use:**

- Declare lookup tables for enrichment (e.g., threat intel, asset inventory)
- Define GeoIP contexts for IP address geolocation
- Specify other stateful resources your operators need

Contexts are defined in `package.yaml` and must be created/populated separately in the Tenzir node.

### `package_add_test` <Badge text="Packaging" variant="tip" />

**When to use:**

- Create test cases for your operators
- Define expected behavior with input/output pairs
- Set up integration tests with fixtures (e.g., embedded Tenzir nodes)
- Generate test scaffolds to be populated later with `run_test`

Tests use the `tenzir-test` framework. Provide input/output when known, or omit and use `run_test` with `update=True` to generate baselines.

**Example:**

```python
# Test with input/output
package_add_test(
    package_dir="/tmp/my-package",
    test="from stdin | my_package::parse",
    input='{"message": "test"}'
)

# Test with inline data
package_add_test(
    package_dir="/tmp/my-package",
    test='from {message: "test"} | my_package::parse',
    fixtures=["node"]
)
```

### `package_add_changelog` <Badge text="Packaging" variant="tip" />

**When to use:**

- Document changes to your package
- Track breaking changes, new features, bug fixes, and general changes
- Maintain a history of package evolution
- Communicate updates to package users

Changelog entries are timestamped and categorized, helping users understand version changes.

**Example:**

```python
package_add_changelog(
    package_dir="/tmp/my-package",
    type="feature",
    description="Initial release with custom parser"
)
```

### `make_parser` <Badge text="Coding" variant="note" />

**When to use:**

- You have sample log events and need to parse them into structured data
- You're starting a new parser for JSON, CSV, syslog, or key-value logs
- You want guidance on format detection and TQL operator selection
- You need to infer types and create proper schema transformations

This tool provides a complete workflow with step-by-step instructions for analyzing log format, selecting TQL operators, generating parsing code, creating a package, and testing.

**Supported Formats:** JSON, CSV, syslog (RFC 3164/5424), key-value pairs

**Example:**

```python
make_parser(sample='''
{"timestamp": "2024-01-01T00:00:00Z", "level": "INFO", "message": "test"}
{"timestamp": "2024-01-01T00:01:00Z", "level": "ERROR", "message": "fail"}
''')
# Returns workflow instructions for format detection, parser generation, and testing
```

### `make_ocsf_mapping` <Badge text="Coding" variant="note" />

**When to use:**

- You need to map security logs to the OCSF standard
- You're normalizing data from multiple sources into a common schema
- You want to make your data compatible with OCSF-aware tools
- You need guidance on OCSF class selection and field mapping

This tool provides a complete workflow with step-by-step instructions for analyzing your data, identifying the appropriate OCSF class, creating field mappings, generating TQL operators, and testing the transformation.

**Example:**

```python
make_ocsf_mapping(sample='''
{"src_ip": "10.0.0.1", "dst_ip": "192.168.1.1", "proto": "tcp", "port": 443}
{"src_ip": "10.0.0.2", "dst_ip": "192.168.1.2", "proto": "udp", "port": 53}
''')
# Returns workflow instructions for OCSF class selection, field mapping, and testing
```

## Recommended Workflows

### Quick Parser Generation

For generating a parser from sample logs:

1. **Get workflow instructions**: Call `make_parser` with sample events to receive detailed workflow instructions.
2. **Follow the workflow**: The tool provides step-by-step guidance for format detection, parser generation, and testing.
3. **Test the parser**: Use `run_pipeline` to test the generated TQL code with sample data.
4. **Create package**: Use `package_create`, `package_add_operator`, and `package_add_test` to formalize the parser.

### OCSF Mapping Package

For creating a complete OCSF mapping package:

1. **Get workflow instructions**: Call `make_ocsf_mapping` with sample events to receive detailed workflow instructions.
2. **Follow the workflow**: The tool provides guidance for OCSF class detection, field mapping, and operator generation.
3. **Create operators**: Use `package_add_operator` to add the mapping operator to your package.
4. **Add tests**: Use `package_add_test` to create test cases for the mapping.
5. **Update test baseline**: Run `run_test` with `update=True` to generate expected outputs.
6. **Verify mappings**: Review and adjust field mappings as needed.

### Manual Package Development

For building a package from scratch:

1. **Create scaffold**: Call `package_create` to set up the structure.
2. **Research operators**: Use `docs_search` to find relevant operators, then `docs_read` to study them.
3. **Add operators**: Call `package_add_operator` for each UDO, with code `make_parser` generates or manual TQL.
4. **Add tests**: Call `package_add_test` to create test scaffolds.
5. **Run and iterate**: Use `run_test` to execute tests, `run_pipeline` to debug.
6. **Document changes**: Call `package_add_changelog` for each significant change.

### Documentation Discovery

Before writing any TQL:

1. **Search for operators**: `docs_search(query="keyword", search_type="operators")`
2. **Read operator docs**: `docs_read(path="reference/operators/<name>")`  
   **Critical**: Always read documentation before using operators!
3. **Explore related**: Use `depth=1` in `docs_search` to discover related operators.
4. **List all**: `docs_read(path="reference/operators")` to see all available operators.
