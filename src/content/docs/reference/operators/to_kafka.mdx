---
title: to_kafka
category: Outputs/Events
example: 'to_kafka "topic", message=this.print_json()'
---

import Op from '@components/see-also/Op.astro';
import Integration from '@components/see-also/Integration.astro';
import AWSIAMOptions from '@partials/operators/AWSIAMOptions.mdx';

Sends messages to an Apache Kafka topic.

```tql
to_kafka topic:string, [message=blob|string, key=string, timestamp=time,
         options=record, aws_iam=record, aws_region=string]
```

## Description

The `to_kafka` operator sends one message per event to a Kafka topic.

The implementation uses the official [librdkafka][librdkafka] from Confluent and
supports all [configuration options][librdkafka-options]. You can specify them
via `options` parameter as `{key: value, ...}`.

[librdkafka]: https://github.com/confluentinc/librdkafka
[librdkafka-options]: https://github.com/confluentinc/librdkafka/blob/master/CONFIGURATION.md

The operator injects the following default librdkafka configuration values in
case no configuration file is present, or when the configuration does not
include them:

- `bootstrap.servers`: `localhost`
- `client.id`: `tenzir`

### `topic: string`

The Kafka topic to send messages to.

### `message = blob|string (optional)`

An expression that evaluates to the message content for each row.

Defaults to `this.print_json()` when not specified.

### `key = string (optional)`

Sets a fixed key for all messages.

### `timestamp = time (optional)`

Sets a fixed timestamp for all messages.

### `options = record (optional)`

A record of key-value configuration options for
[librdkafka][librdkafka], e.g., `{"acks": "all", "batch.size": 16384}`.

The `to_kafka` operator passes the key-value pairs directly to
[librdkafka][librdkafka]. Consult the list of available [configuration
options][librdkafka-options] to configure Kafka according to your needs.

We recommend factoring these options into the plugin-specific `kafka.yaml` so
that they are independent of the `to_kafka` arguments.

<AWSIAMOptions />

### `aws_region = string (optional)`

The AWS region used to construct the MSK authentication URL. Required when
connecting to MSK with IAM authentication.

## Examples

### Send JSON-formatted events to topic `events` (using default)

Stream security events to a Kafka topic with automatic JSON formatting:

```tql
subscribe "security-alerts"
where severity >= "high"
select timestamp, source_ip, alert_type, details
to_kafka "events"
```

This pipeline subscribes to security alerts, filters for high-severity events,
selects relevant fields, and sends them to Kafka as JSON. Each event is
automatically formatted using `this.print_json()`, producing messages like:

```json
{
  "timestamp": "2024-03-15T10:30:00.000000",
  "source_ip": "192.168.1.100",
  "alert_type": "brute_force",
  "details": "Multiple failed login attempts detected"
}
```

### Send JSON-formatted events with explicit message

```tql
subscribe "logs"
to_kafka "events", message=this.print_json()
```

### Send specific field values with a timestamp

```tql
subscribe "logs"
to_kafka "alerts", message=alert_msg, timestamp=2024-01-01T00:00:00
```

### Send data with a fixed key for partitioning

```tql
metrics
to_kafka "metrics", message=this.print_json(), key="server-01"
```

## See Also

- <Op>from_kafka</Op>
- <Integration>kafka</Integration>
