---
title: save_kafka
category: Outputs/Bytes
example: 'save_kafka topic="example"'
---

import Op from '@components/see-also/Op.astro';
import Integration from '@components/see-also/Integration.astro';
import AWSIAMOptions from '@partials/operators/AWSIAMOptions.mdx';

Saves a byte stream to a Apache Kafka topic.

```tql
save_kafka topic:string, [key=string, timestamp=time, options=record,
           aws_iam=record]
```

## Description

:::caution[Deprecated]
The `save_kafka` operator does not respect event boundaries and can combine
multiple events into a single message, causing issues for consumers. Consider
using [`to_kafka`](/reference/operators/to_kafka) instead.
:::

The `save_kafka` operator saves bytes to a Kafka topic.

The implementation uses the official [librdkafka][librdkafka] from Confluent and
supports all [configuration options][librdkafka-options]. You can specify them
via `options` parameter as `{key: value, ...}`.

[librdkafka]: https://github.com/confluentinc/librdkafka
[librdkafka-options]: https://github.com/confluentinc/librdkafka/blob/master/CONFIGURATION.md

The operator injects the following default librdkafka configuration values in
case no configuration file is present, or when the configuration does not
include them:

- `bootstrap.servers`: `localhost`
- `client.id`: `tenzir`
- `group.id`: `tenzir`

### `topic: string`

The Kafka topic to use.

### `key = string (optional)`

Sets a fixed key for all messages.

### `timestamp = time (optional)`

Sets a fixed timestamp for all messages.

### `options = record (optional)`

A record of key-value configuration options for
[librdkafka][librdkafka], e.g., `{"auto.offset.reset" : "earliest",
"enable.partition.eof": true}`.

The `save_kafka` operator passes the key-value pairs directly to
[librdkafka][librdkafka]. Consult the list of available [configuration
options][librdkafka-options] to configure Kafka according to your needs.

We recommend factoring these options into the plugin-specific `kafka.yaml` so
that they are independent of the `save_kafka` arguments.

Enables AWS IAM authentication for MSK (Amazon Managed Streaming for Apache
Kafka). When using MSK, the `region` field must be specified.

<AWSIAMOptions />

## Examples

### Write the Tenzir version to topic `tenzir` with timestamp from the past

```tql
version
write_json
save_kafka "tenzir", timestamp=1984-01-01
```

### Follow a CSV file and publish it to topic `data`

```tql
load_file "/tmp/data.csv"
read_csv
write_json
save_kafka "data"
```

## See Also

- <Op>from_kafka</Op>
- <Op>to_kafka</Op>
- <Integration>kafka</Integration>
